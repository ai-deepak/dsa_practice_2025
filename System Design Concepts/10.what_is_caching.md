# Understanding Caching

## What is Caching?

Caching is a technique used to improve system performance by storing frequently accessed data in a faster storage location. The goal is to reduce expensive operations such as:

- **Network I/O** (e.g., API calls to remote services)
- **Disk I/O** (e.g., reading from a database or file system)
- **CPU-intensive computations** (e.g., complex queries, expensive calculations)

By keeping frequently used data in a faster storage medium, we avoid redundant expensive operations, improving overall system efficiency.

---

## How Caching Works

### The General Flow

1. A request is made to the API server.
2. The API server checks the cache.
   - If the data is **found** in the cache → Return it immediately.
   - If the data is **not found** in the cache → Fetch it from the database.
3. The API server processes the request and stores the result in the cache.
4. Future requests fetch data from the cache instead of the database.

This reduces expensive database queries and speeds up response times.

![alt text](image-12.png)

### Example: Caching User Profile Information

Consider an application that retrieves a user’s profile information:

1. A request is made for a user's profile.
2. The API server checks if the profile is in the cache (e.g., Redis, Memcached).
3. If found, the API server returns the cached profile.
4. If not found, the API server queries the database, joins multiple tables, and constructs the profile.
5. The response is cached to avoid repeated expensive computations.

---

## Types of Caching

### 1. **In-Memory Caching**

- Stores data in **RAM** for fast access.
- Examples: **Redis, Memcached**.
- Used for storing session data, frequently accessed queries, or computed values.

### 2. **Database Caching**

- Caches results of expensive database queries.
- Example: **Materialized Views** in SQL databases.
- Used to reduce database load and improve read performance.

### 3. **Application-Level Caching**

- Stores frequently used data at the application level.
- Example: **Caching within API servers** to avoid redundant processing.

### 4. **CDN Caching**

- Used to cache static content like images, CSS, JavaScript.
- Example: **Cloudflare, Akamai, AWS CloudFront**.
- Improves website performance by serving content from edge locations.

### 5. **Browser Caching**

- Stores static files in the user’s browser to avoid reloading.
- Example: **Caching JavaScript, CSS, and images**.

---

## Key Considerations for Caching

### 1. **Cache Invalidation**

- Cached data should be updated when the underlying data changes.
- Strategies include **time-based expiration (TTL)** and **event-driven invalidation**.

### 2. **Cache Eviction Policies**

Since cache storage (RAM) is limited, old or unused data must be removed. Common policies include:

- **LRU (Least Recently Used):** Removes the least recently accessed item.
- **LFU (Least Frequently Used):** Removes the least frequently accessed item.
- **FIFO (First In, First Out):** Removes the oldest stored item.

### 3. **Cache Storage Location**

- Caches should be **nearer** to the application to minimize latency.
- **Example:** Using an API server's local memory instead of querying a remote database.

### 4. **Cost Consideration**

- RAM is expensive, so cache **only frequently accessed data**.
- Example: Instead of caching all tweets, cache only the most recent ones.

---

## Real-World Caching Examples

### **1. Twitter Feed Caching**

- Recent tweets are cached because they are accessed frequently.
- Reduces database load by serving cached tweets.

### **2. Google News Caching**

- Newly published articles are cached as they are accessed the most.
- Older news articles are accessed less frequently and may not be cached.

### **3. Authentication Token Caching**

- API servers cache authentication tokens to avoid validating them against the database on every request.
- Reduces database load and speeds up authentication.

### **4. Live Streaming Caching**

- Content Delivery Networks (CDNs) cache recent streaming content.
- Example: Streaming the last 10 minutes of a live cricket match.
- Prevents unnecessary database calls and reduces latency.

---

## Common Caching Technologies

1. **Redis** - An in-memory key-value store with advanced caching capabilities.
2. **Memcached** - A simpler key-value store focused on high-performance caching.
3. **CDN Services** - Cloudflare, Akamai, AWS CloudFront for web content caching.
4. **Local Storage Caching** - Caching frequently used data within API servers.

---

## Conclusion

Caching is a critical performance optimization technique that reduces expensive network, disk, and computational operations. By carefully choosing what to cache, where to store it, and when to invalidate it, applications can achieve significant performance improvements while minimizing infrastructure costs.

Caching is **not just about RAM**—it is about storing frequently accessed data closer to where it is needed, whether in memory, a CDN, or even within the API server itself.
